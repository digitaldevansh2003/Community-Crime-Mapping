{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digitaldevansh2003/Community-Crime-Mapping/blob/main/Multivariate%20dataset%20HousePricePrediction%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfa31bf",
      "metadata": {
        "id": "9dfa31bf"
      },
      "source": [
        "# Installation of Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "eab23f2a",
      "metadata": {
        "id": "eab23f2a"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Importing the NumPy library and renaming it to \"np\"\n",
        "import pandas as pd  # Importing the Pandas library and renaming it to \"pd\"\n",
        "import matplotlib.pyplot as plt  # Importing the Pyplot module from the Matplotlib library and renaming it to \"plt\"\n",
        "import seaborn as sns  # Importing the Seaborn library and renaming it to \"sns\"\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "id": "bVh17gOEJXhp",
        "outputId": "0305dfdf-2cb7-4012-85a8-571a0f63fa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "id": "bVh17gOEJXhp",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3fe852c7-e2ca-4a87-9322-abdf6e4d27db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3fe852c7-e2ca-4a87-9322-abdf6e4d27db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bengaluru_House_Data.csv to Bengaluru_House_Data (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0IT_stSxJYjw"
      },
      "id": "0IT_stSxJYjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "189dd6f6",
      "metadata": {
        "id": "189dd6f6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Bengaluru_House_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "577c3e82",
      "metadata": {
        "id": "577c3e82",
        "outputId": "05490dcc-3a6d-467a-ff48-5eb9beaf8462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-96afb4a6f559>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reading the first few data from the top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "#reading the first few data from the top\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aad9e7e",
      "metadata": {
        "id": "6aad9e7e"
      },
      "source": [
        "# Data Preprocessig, Cleaning and Exploratry Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c794d6b",
      "metadata": {
        "id": "3c794d6b",
        "outputId": "07887808-1feb-45d7-f1a1-f4d28ee11960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7b287636b1ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#checking the shape of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "#checking the shape of the dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "734fa212",
      "metadata": {
        "id": "734fa212",
        "outputId": "44d78375-7b86-420e-e06d-920869fa242e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb08788731df>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#counting all the null values present in the each columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "#counting all the null values present in the each columns\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f5e6df",
      "metadata": {
        "id": "f7f5e6df"
      },
      "outputs": [],
      "source": [
        "#plotting the heatmap to check the null values in datset (visual representation)\n",
        "plt.figure(figsize=(16,16))\n",
        "sns.heatmap(df.isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d5780b",
      "metadata": {
        "id": "58d5780b"
      },
      "outputs": [],
      "source": [
        "#calculating the percentage of missing data in the dataset\n",
        "df.isnull().sum()/df.shape[0]*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8575d8",
      "metadata": {
        "id": "2f8575d8"
      },
      "source": [
        "## Here, the data will be preprocessed for model fitting. In the first scenario, all the columns having category values will be eliminated, and only the columns with numeric values would be processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221ebbcd",
      "metadata": {
        "id": "221ebbcd"
      },
      "outputs": [],
      "source": [
        "df.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0cc85b",
      "metadata": {
        "id": "0b0cc85b"
      },
      "outputs": [],
      "source": [
        "#we will drop the columns containg categorical value and a coolumn which has a null value more 20%\n",
        "df_drop = df.drop(columns=['area_type','availability','location','society'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a235c6",
      "metadata": {
        "id": "32a235c6"
      },
      "outputs": [],
      "source": [
        "df_drop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b36a357",
      "metadata": {
        "id": "6b36a357"
      },
      "outputs": [],
      "source": [
        "#since, we want to predict the price of the hosue we need to check the types of data present in the dataset\n",
        "df_drop.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f4d154",
      "metadata": {
        "id": "14f4d154"
      },
      "outputs": [],
      "source": [
        "# size and total_sqft are two columns present in object type data, so we need to convert that object Dtype into Float/int Dtype\n",
        "df_drop['size'].unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d016cd",
      "metadata": {
        "id": "25d016cd"
      },
      "outputs": [],
      "source": [
        "#it seems that column size has both string and integer stored together in the dataset. so we will sepearte integer from the str value\n",
        "df_drop['bhk'] = pd.to_numeric(df_drop['size'].str.extract('(\\d+)')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8261f7",
      "metadata": {
        "id": "4e8261f7"
      },
      "outputs": [],
      "source": [
        "df_drop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31592210",
      "metadata": {
        "id": "31592210"
      },
      "outputs": [],
      "source": [
        "df_drop[50:60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cf9a18",
      "metadata": {
        "id": "c3cf9a18"
      },
      "outputs": [],
      "source": [
        "#we have extracted numeric value from column size so we will drop that column as well\n",
        "df_drop.drop(columns=['size'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f8d2f6",
      "metadata": {
        "id": "a6f8d2f6"
      },
      "outputs": [],
      "source": [
        "df_drop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f344643",
      "metadata": {
        "id": "8f344643"
      },
      "outputs": [],
      "source": [
        "df_drop.isnull().sum(),df_drop.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cdbad9f",
      "metadata": {
        "id": "3cdbad9f"
      },
      "outputs": [],
      "source": [
        "df_drop.isnull().sum()/df_drop.shape[0]*100, df_drop.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d66cac",
      "metadata": {
        "id": "c7d66cac"
      },
      "outputs": [],
      "source": [
        "#plotting heatmap to see the missing value present in the new dataframe after dropping the columns\n",
        "plt.figure(figsize=(16,16))\n",
        "sns.heatmap(df_drop.isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e157f1f",
      "metadata": {
        "id": "6e157f1f"
      },
      "outputs": [],
      "source": [
        "#here the range value are converted into single integer\n",
        "def convertRange_into_singleinteger(a):\n",
        "    try:\n",
        "        return float(a)\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        lower_bound, upper_bound = map(float, a.split('-'))\n",
        "        return (lower_bound + upper_bound) / 2\n",
        "    except ValueError:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f76984",
      "metadata": {
        "id": "00f76984"
      },
      "outputs": [],
      "source": [
        "#after converting the range value into float type we applied the changes into dataframe\n",
        "df_drop['total_sqft'] = df_drop['total_sqft'].apply(convertRange_into_singleinteger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e272e3",
      "metadata": {
        "id": "f8e272e3"
      },
      "outputs": [],
      "source": [
        "df_drop.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4166552f",
      "metadata": {
        "id": "4166552f"
      },
      "outputs": [],
      "source": [
        "#checking the null value percentages\n",
        "df_drop.isnull().sum()/df_drop.shape[0]*100, df_drop.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b60003cd",
      "metadata": {
        "id": "b60003cd"
      },
      "source": [
        "## There are several approaches to handling missing values in a dataset. Since the missing values are less than one %, we will first remove the row that contains them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b7ea32",
      "metadata": {
        "id": "a0b7ea32"
      },
      "outputs": [],
      "source": [
        "new_df_drop = df_drop.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "884ba32b",
      "metadata": {
        "id": "884ba32b"
      },
      "outputs": [],
      "source": [
        "#checking the missing value after dropping the rows which contains missing value\n",
        "new_df_drop.isnull().sum(),new_df_drop.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c687ed",
      "metadata": {
        "id": "09c687ed"
      },
      "source": [
        "# Now we will perform Feature Engineering to analyze the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c03251f",
      "metadata": {
        "id": "1c03251f"
      },
      "outputs": [],
      "source": [
        "new_df_drop.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea3714b",
      "metadata": {
        "id": "cea3714b"
      },
      "outputs": [],
      "source": [
        "# Create a figure and three subplots for each boxplot\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, figsize=(15,10))\n",
        "\n",
        "# Create the first boxplot for total_sqft\n",
        "ax1.boxplot(new_df_drop['total_sqft'])\n",
        "ax1.set_title('total_sqft 1')\n",
        "\n",
        "# Create the second boxplot for bath\n",
        "ax2.boxplot(new_df_drop['bath'])\n",
        "ax2.set_title('bath')\n",
        "\n",
        "# Create the third boxplot for bhk\n",
        "ax3.boxplot(new_df_drop['bhk'])\n",
        "ax3.set_title('bhk')\n",
        "\n",
        "# Create the fourth boxplot for bhk\n",
        "ax4.boxplot(new_df_drop['balcony'])\n",
        "ax4.set_title('balcony')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2488108",
      "metadata": {
        "id": "d2488108"
      },
      "source": [
        "### The boxplot shows that the dataset has several outliers. Hence, using the quartile approach, we will eliminate the outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680f9260",
      "metadata": {
        "id": "680f9260"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_quartile(new_df_drop, total_sqft):\n",
        "    q1 = new_df_drop[total_sqft].quantile(0.25)\n",
        "    q3 = new_df_drop[total_sqft].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_limit = q1 - 1.5 * iqr\n",
        "    upper_limit = q3 + 1.5 * iqr\n",
        "    df_filtered = new_df_drop[(new_df_drop[total_sqft] > lower_limit) & (new_df_drop[total_sqft] < upper_limit)]\n",
        "    return df_filtered\n",
        "new_df2 = remove_outliers_quartile(new_df_drop, 'total_sqft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbff34ae",
      "metadata": {
        "id": "bbff34ae"
      },
      "outputs": [],
      "source": [
        "#checking the difference between dataset before and after removing outliers\n",
        "print(len(new_df_drop)-len(new_df2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d71d28",
      "metadata": {
        "id": "86d71d28"
      },
      "outputs": [],
      "source": [
        "new_df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11e7e40",
      "metadata": {
        "id": "b11e7e40"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_quartile(new_df2, bath):\n",
        "    q1 = new_df2[bath].quantile(0.25)\n",
        "    q3 = new_df2[bath].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_limit = q1 - 1.5 * iqr\n",
        "    upper_limit = q3 + 1.5 * iqr\n",
        "    df1_filtered = new_df2[(new_df2[bath] >= lower_limit) & (new_df2[bath] <= upper_limit)]\n",
        "    return df1_filtered\n",
        "new_df3 = remove_outliers_quartile(new_df2, 'bath')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17690444",
      "metadata": {
        "id": "17690444"
      },
      "outputs": [],
      "source": [
        "print(len(new_df2)-len(new_df3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273372a3",
      "metadata": {
        "id": "273372a3"
      },
      "outputs": [],
      "source": [
        "new_df3.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359d45f5",
      "metadata": {
        "id": "359d45f5"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_quartile(new_df3, bhk):\n",
        "    q1 = new_df3[bhk].quantile(0.25)\n",
        "    q3 = new_df3[bhk].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_limit = q1 - 1.5 * iqr\n",
        "    upper_limit = q3 + 1.5 * iqr\n",
        "    df2_filtered = new_df3[(new_df2[bhk] >= lower_limit) & (new_df3[bhk] <= upper_limit)]\n",
        "    return df2_filtered\n",
        "new_df4 = remove_outliers_quartile(new_df3, 'bhk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fbd0c92",
      "metadata": {
        "id": "6fbd0c92"
      },
      "outputs": [],
      "source": [
        "print(len(new_df3)-len(new_df4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ea9613",
      "metadata": {
        "id": "17ea9613"
      },
      "outputs": [],
      "source": [
        "new_df4.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a88a1d",
      "metadata": {
        "id": "31a88a1d"
      },
      "outputs": [],
      "source": [
        "new_df4.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbe690a",
      "metadata": {
        "id": "bbbe690a"
      },
      "outputs": [],
      "source": [
        "colors = ['pink', 'lightblue', 'lightgreen', 'yellow']\n",
        "# Create a figure and three subplots for each boxplot\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, figsize=(15,10))\n",
        "\n",
        "# Create the first boxplot for total_sqft\n",
        "ax1.boxplot(new_df4['total_sqft'])\n",
        "ax1.set_title('total_sqft 1')\n",
        "\n",
        "# Create the second boxplot for bath\n",
        "ax2.boxplot(new_df4['bath'])\n",
        "ax2.set_title('bath')\n",
        "\n",
        "# Create the third boxplot for bhk\n",
        "ax3.boxplot(new_df4['bhk'])\n",
        "ax3.set_title('bhk')\n",
        "\n",
        "# Create the fourth boxplot for bhk\n",
        "ax4.boxplot(new_df4['balcony'])\n",
        "ax4.set_title('balcony')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf88abe",
      "metadata": {
        "id": "2bf88abe"
      },
      "outputs": [],
      "source": [
        "#after the preprocessing of data saving the cleaned data into csv\n",
        "new_df4.to_csv(\"cleaned_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da549617",
      "metadata": {
        "id": "da549617"
      },
      "outputs": [],
      "source": [
        "Cleaned_data_ML = pd.read_csv('cleaned_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5ad281",
      "metadata": {
        "id": "be5ad281"
      },
      "outputs": [],
      "source": [
        "Cleaned_data_ML.head(),Cleaned_data_ML.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabd0da1",
      "metadata": {
        "id": "fabd0da1"
      },
      "source": [
        "# Model training and Evaluation\n",
        "### Splitting cleaned dataset into training and testing dataset and performing ML algorithim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a78c4edd",
      "metadata": {
        "id": "a78c4edd"
      },
      "outputs": [],
      "source": [
        "x = Cleaned_data_ML[['total_sqft','bath','bhk']]\n",
        "y = Cleaned_data_ML['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851c1a07",
      "metadata": {
        "id": "851c1a07"
      },
      "outputs": [],
      "source": [
        "#importing all the necessary libraries to perform the ML task\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5acee94",
      "metadata": {
        "id": "d5acee94"
      },
      "outputs": [],
      "source": [
        "#splitting the dataset into train, test and split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.25, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4797311",
      "metadata": {
        "id": "c4797311"
      },
      "outputs": [],
      "source": [
        "#standardize the numerical variables\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb75b649",
      "metadata": {
        "id": "fb75b649"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d257ee",
      "metadata": {
        "id": "83d257ee"
      },
      "outputs": [],
      "source": [
        "#chain multiple preprocessing and modeling steps into a single pipeline\n",
        "pipe1 = make_pipeline(scaler, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6403760",
      "metadata": {
        "id": "b6403760"
      },
      "outputs": [],
      "source": [
        "#training a machine learning model using a pipeline that preprocesses the data and trains the model\n",
        "pipe1.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1725e788",
      "metadata": {
        "id": "1725e788"
      },
      "outputs": [],
      "source": [
        "# evaluating a linear regression model's performance on a set of test data\n",
        "y_prediction_lr = list(pipe1.predict(x_test))\n",
        "r2_score(y_test, y_prediction_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12539c9d",
      "metadata": {
        "id": "12539c9d"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_lr = mean_squared_error(y_test, y_prediction_lr)\n",
        "mae_lr = mean_absolute_error(y_test, y_prediction_lr)\n",
        "print(\"Mean Squared Error:\", mse_lr)\n",
        "print(\"Mean Absolute Error:\", mae_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed9e156",
      "metadata": {
        "id": "6ed9e156"
      },
      "outputs": [],
      "source": [
        "#creating an instance of the Lasso class from the Scikit-learn library.\n",
        "ls = Lasso()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d95d2e",
      "metadata": {
        "id": "f3d95d2e"
      },
      "outputs": [],
      "source": [
        "pipe2 = make_pipeline(scaler, ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea38992f",
      "metadata": {
        "id": "ea38992f"
      },
      "outputs": [],
      "source": [
        "pipe2.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e37553c",
      "metadata": {
        "id": "2e37553c"
      },
      "outputs": [],
      "source": [
        "y_prediction_ls = list(pipe2.predict(x_test))\n",
        "r2_score(y_test, y_prediction_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791246ee",
      "metadata": {
        "id": "791246ee"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_ls = mean_squared_error(y_test, y_prediction_ls)\n",
        "mae_ls = mean_absolute_error(y_test, y_prediction_ls)\n",
        "print(\"Mean Squared Error:\", mse_ls)\n",
        "print(\"Mean Absolute Error:\", mae_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cccaaf1c",
      "metadata": {
        "id": "cccaaf1c"
      },
      "outputs": [],
      "source": [
        "##creating an instance of the ridge class from the Scikit-learn library.\n",
        "rg = Ridge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff2d7ea",
      "metadata": {
        "id": "fff2d7ea"
      },
      "outputs": [],
      "source": [
        "pipe3 = make_pipeline(scaler, rg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc11da69",
      "metadata": {
        "id": "dc11da69"
      },
      "outputs": [],
      "source": [
        "pipe3.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40340d5",
      "metadata": {
        "id": "d40340d5"
      },
      "outputs": [],
      "source": [
        "y_prediction_rg = list(pipe3.predict(x_test))\n",
        "r2_score(y_test, y_prediction_rg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd7e5a0",
      "metadata": {
        "id": "1cd7e5a0"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_rg = mean_squared_error(y_test, y_prediction_rg)\n",
        "mae_rg = mean_absolute_error(y_test, y_prediction_rg)\n",
        "print(\"Mean Squared Error:\", mse_rg)\n",
        "print(\"Mean Absolute Error:\", mae_rg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbfd6e3",
      "metadata": {
        "id": "3bbfd6e3"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "model = SVR()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86547d5b",
      "metadata": {
        "id": "86547d5b"
      },
      "outputs": [],
      "source": [
        "pipe4 = make_pipeline(scaler, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43e270e",
      "metadata": {
        "id": "c43e270e"
      },
      "outputs": [],
      "source": [
        "pipe4.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b6f625",
      "metadata": {
        "id": "75b6f625"
      },
      "outputs": [],
      "source": [
        "y_prediction_svr = list(pipe4.predict(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e461db",
      "metadata": {
        "id": "24e461db"
      },
      "outputs": [],
      "source": [
        "pipe4.score(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d8555b",
      "metadata": {
        "id": "07d8555b"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_svr = mean_squared_error(y_test, y_prediction_svr)\n",
        "mae_svr = mean_absolute_error(y_test, y_prediction_svr)\n",
        "print(\"Mean Squared Error:\", mse_svr)\n",
        "print(\"Mean Absolute Error:\", mae_svr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6406f0",
      "metadata": {
        "id": "0c6406f0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df104508",
      "metadata": {
        "id": "df104508"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b23687",
      "metadata": {
        "id": "95b23687"
      },
      "outputs": [],
      "source": [
        "pipe5 = make_pipeline(scaler, rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "930b32f6",
      "metadata": {
        "id": "930b32f6"
      },
      "outputs": [],
      "source": [
        "pipe5.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55577c3f",
      "metadata": {
        "id": "55577c3f"
      },
      "outputs": [],
      "source": [
        "y_prediction_rf = list(pipe5.predict(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08cc23cf",
      "metadata": {
        "id": "08cc23cf"
      },
      "outputs": [],
      "source": [
        "pipe5.score(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf00f521",
      "metadata": {
        "id": "bf00f521"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_rf = mean_squared_error(y_test, y_prediction_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_prediction_rf)\n",
        "print(\"Mean Squared Error:\", mse_rf)\n",
        "print(\"Mean Absolute Error:\", mae_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b154c001",
      "metadata": {
        "id": "b154c001"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a79a06e",
      "metadata": {
        "id": "1a79a06e"
      },
      "outputs": [],
      "source": [
        "print('LinearRegression Accuracy:', r2_score(y_test, y_prediction_lr))\n",
        "print('Lasso Accuracy:', r2_score(y_test, y_prediction_ls))\n",
        "print('Ridge Accuracy:', r2_score(y_test, y_prediction_rg))\n",
        "\n",
        "print('Support Vector Regressor Accuracy:', pipe4.score(x_test,y_test))\n",
        "print('RandomForest Regressor Accuracy:', pipe5.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6b02e8",
      "metadata": {
        "id": "7b6b02e8"
      },
      "outputs": [],
      "source": [
        "print(\"Mean Squared Error Linear Regression:\", mse_lr)\n",
        "print(\"Mean Absolute Error Linear Regression:\", mae_lr)\n",
        "print()\n",
        "print(\"Mean Squared Error Lasso:\", mse_ls)\n",
        "print(\"Mean Absolute Error Lasso:\", mae_ls)\n",
        "print()\n",
        "print(\"Mean Squared Error Ridge:\", mse_rg)\n",
        "print(\"Mean Absolute Error Ridge:\", mae_rg)\n",
        "print()\n",
        "print(\"Mean Squared Error Support Vector Regressor:\", mse_svr)\n",
        "print(\"Mean Absolute Error Support Vector Regressor:\", mae_svr)\n",
        "print()\n",
        "print(\"Mean Squared Error Random Forest:\", mse_rf)\n",
        "print(\"Mean Absolute ErrorRandom Forest:\", mae_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45318b1c",
      "metadata": {
        "id": "45318b1c"
      },
      "source": [
        "## We feel embarrassed after seeing the results because the models' accuracy is so poor. As a result, we will preprocess the data once again but in a different way. We will now take into account the location as it is important in determining the price of the house. Also, we should tackle outliers in a different manner."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0c8b62",
      "metadata": {
        "id": "7d0c8b62"
      },
      "source": [
        "# Data Preprocessig, Cleaning and Exploratry Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15b0927",
      "metadata": {
        "id": "f15b0927"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a0bec2d",
      "metadata": {
        "id": "1a0bec2d"
      },
      "outputs": [],
      "source": [
        "#dropping the columns containing categorical value and column which has null value more than 20%\n",
        "whole_new_df = df.drop(columns=['area_type','availability','society','balcony'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91a6e42",
      "metadata": {
        "id": "f91a6e42"
      },
      "outputs": [],
      "source": [
        "whole_new_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b1ab086",
      "metadata": {
        "id": "3b1ab086"
      },
      "source": [
        "# Now we will tackle each attribute carefully and make it clean for feeding it to our machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c55efeb",
      "metadata": {
        "id": "7c55efeb"
      },
      "outputs": [],
      "source": [
        "whole_new_df.isnull().sum(), whole_new_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc4a3485",
      "metadata": {
        "id": "bc4a3485"
      },
      "source": [
        "## Given that there is only one missing value for the location column, we may fill it with the value that has been used the most frequently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af986343",
      "metadata": {
        "id": "af986343"
      },
      "outputs": [],
      "source": [
        "#count the each instance in column 'location'\n",
        "#for column in whole_new_df.columns:\n",
        "#    value_counts = whole_new_df[column].value_counts()\n",
        " #   print(f'Counts for {column}:')\n",
        "  #  print(value_counts)\n",
        "   # print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf6facd",
      "metadata": {
        "id": "eaf6facd"
      },
      "outputs": [],
      "source": [
        "#count the each instance in column 'location'\n",
        "whole_new_df['location'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8d262d",
      "metadata": {
        "id": "af8d262d"
      },
      "outputs": [],
      "source": [
        "#now we will fill the missing value with mode value in the column location\n",
        "whole_new_df['location'] = whole_new_df['location'].fillna(whole_new_df['location'].mode().iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8632d412",
      "metadata": {
        "id": "8632d412"
      },
      "outputs": [],
      "source": [
        "#checking percentage of null value in the dataset\n",
        "whole_new_df.isnull().sum(), whole_new_df.isnull().sum()/whole_new_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57c18bb",
      "metadata": {
        "id": "f57c18bb"
      },
      "source": [
        "## Because the location column has no longer missing a value, we can move on to the size. We can estimate the dataset's mode value for that specific column since the missing value is less than one percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e9b3ff",
      "metadata": {
        "id": "d2e9b3ff"
      },
      "outputs": [],
      "source": [
        "whole_new_df['size'] = whole_new_df['size'].fillna(whole_new_df['size'].mode().iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b0a299",
      "metadata": {
        "id": "29b0a299"
      },
      "outputs": [],
      "source": [
        "whole_new_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5ed44f",
      "metadata": {
        "id": "5c5ed44f"
      },
      "outputs": [],
      "source": [
        "whole_new_df['bath'] = whole_new_df['bath'].fillna(whole_new_df['bath'].mode().iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a6570a",
      "metadata": {
        "id": "c2a6570a"
      },
      "outputs": [],
      "source": [
        "#after filling the missing value in the dataset checking the status of the dataset\n",
        "whole_new_df.isnull().sum(), whole_new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74bae56c",
      "metadata": {
        "id": "74bae56c"
      },
      "outputs": [],
      "source": [
        "#plotting heatmap to check if there are any missing value present in the dataset\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(whole_new_df.isnull())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fafa16d0",
      "metadata": {
        "id": "fafa16d0"
      },
      "source": [
        "## We substituted the most often repeated values for the few missing values that were present. Considering the data's distribution might also help you decide whether to use the mean, median, or mode to fill in the missing number.\n",
        "## Now, we dont have any missing value in the dataset, so we will convert the object type data into float type or int type to make it suitbale for feeding into machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0c6e09",
      "metadata": {
        "id": "da0c6e09"
      },
      "outputs": [],
      "source": [
        "#extracting int from column size\n",
        "whole_new_df['size_bhk'] = pd.to_numeric(df['size'].str.extract('(\\d+)')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910f32ec",
      "metadata": {
        "id": "910f32ec"
      },
      "outputs": [],
      "source": [
        "whole_new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dedb72f",
      "metadata": {
        "id": "5dedb72f"
      },
      "outputs": [],
      "source": [
        "whole_new_df['total_sqft'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d00ceca",
      "metadata": {
        "id": "6d00ceca"
      },
      "outputs": [],
      "source": [
        "#here the range value are converted into single integer\n",
        "def convertRange_into_singleinteger(a):\n",
        "    try:\n",
        "        return float(a)\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        lower_bound, upper_bound = map(float, a.split('-'))\n",
        "        return (lower_bound + upper_bound) / 2\n",
        "    except ValueError:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd5f63d",
      "metadata": {
        "id": "bdd5f63d"
      },
      "outputs": [],
      "source": [
        "#apply function to apply the changes in dataset\n",
        "whole_new_df['total_sqft'] = whole_new_df['total_sqft'].apply(convertRange_into_singleinteger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8424e1",
      "metadata": {
        "id": "2e8424e1"
      },
      "outputs": [],
      "source": [
        "whole_new_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e08aef",
      "metadata": {
        "id": "48e08aef"
      },
      "source": [
        "##  At the attribute location, we simply eliminated any leading or trailing white spaces for each value. The locations which had been repeated 20 times or less were then filtered, and they were given the label 'others'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e7ef28",
      "metadata": {
        "id": "40e7ef28"
      },
      "outputs": [],
      "source": [
        "#removing any leading or trailing white spaces of each value in the attribute location\n",
        "whole_new_df['location'] = whole_new_df['location'].apply(lambda x: x.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe25a443",
      "metadata": {
        "id": "fe25a443"
      },
      "outputs": [],
      "source": [
        "location_count = whole_new_df['location'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2682cb59",
      "metadata": {
        "id": "2682cb59"
      },
      "outputs": [],
      "source": [
        "#counting location which has been reptaed only 20 times in the dataset\n",
        "location_count_20 = whole_new_df['location'].value_counts()[location_count<=20]\n",
        "location_count_20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336c0818",
      "metadata": {
        "id": "336c0818"
      },
      "outputs": [],
      "source": [
        "#naming all the location to Others which has been repetated 20 times\n",
        "whole_new_df['location']=whole_new_df['location'].apply(lambda x: 'Other' if x in location_count_20 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92fa9e3",
      "metadata": {
        "id": "f92fa9e3"
      },
      "outputs": [],
      "source": [
        "whole_new_df['location'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a51fd7f2",
      "metadata": {
        "id": "a51fd7f2"
      },
      "outputs": [],
      "source": [
        "whole_new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5db4f3",
      "metadata": {
        "id": "ab5db4f3"
      },
      "outputs": [],
      "source": [
        "whole_new_df.drop(['size'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361fa463",
      "metadata": {
        "id": "361fa463"
      },
      "outputs": [],
      "source": [
        "whole_new_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42984d19",
      "metadata": {
        "id": "42984d19"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(whole_new_df.isnull())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b484c842",
      "metadata": {
        "id": "b484c842"
      },
      "source": [
        " # Now we will perform Feature Engineering to analyze the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4614393e",
      "metadata": {
        "id": "4614393e"
      },
      "source": [
        "### Total sqft has a minimum value of 1, which is impossible. As a result, we'll attempt to filter out the total sqft's real minimum value. To filter the values in the dataset, we will add columns like price per square foot (price per sqft) and bedroom per square foot (bhk per sqft).\n",
        "#### If we take a closer look at the pricing, we can see that it reflects the cost of the entire floor area of the flat. We divide the price by the total square feet of the unit to determine the cost per square foot. We will first multiply the price by 1,000 because it is expressed in thousands of dollars. size has already been converted to size_bhk, we removed the size column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f2db5a",
      "metadata": {
        "id": "47f2db5a"
      },
      "outputs": [],
      "source": [
        "whole_new_df['price_per_sqft'] = whole_new_df['price']*1000/whole_new_df['total_sqft']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7033022",
      "metadata": {
        "id": "a7033022"
      },
      "outputs": [],
      "source": [
        "whole_new_df['bhk_per_sqft'] = whole_new_df['total_sqft']/whole_new_df['size_bhk']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ff679d",
      "metadata": {
        "id": "29ff679d"
      },
      "outputs": [],
      "source": [
        "whole_new_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5a9dea",
      "metadata": {
        "id": "0d5a9dea"
      },
      "source": [
        "### In order to determine the standard deviation of the square footage in one bedroom, we constructed the column bhk per sqft. This will enable us to disregard or eliminate values that are lower than that (387)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7c64f3",
      "metadata": {
        "id": "df7c64f3"
      },
      "outputs": [],
      "source": [
        "whole_new_df = whole_new_df[(whole_new_df['total_sqft']/whole_new_df['size_bhk']>=387)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbcfbd2a",
      "metadata": {
        "id": "fbcfbd2a"
      },
      "outputs": [],
      "source": [
        "whole_new_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf44e3e",
      "metadata": {
        "id": "9cf44e3e"
      },
      "source": [
        "## In order to determine whether or not there are outliers in the dataset, we will create a boxplot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfff3bd1",
      "metadata": {
        "id": "bfff3bd1"
      },
      "outputs": [],
      "source": [
        "# Create a figure and three subplots for each boxplot\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,10))\n",
        "\n",
        "# Create the first boxplot for total_sqft\n",
        "ax1.boxplot(whole_new_df['total_sqft'])\n",
        "ax1.set_title('total_sqft 1')\n",
        "\n",
        "# Create the second boxplot for bath\n",
        "ax2.boxplot(whole_new_df['bath'])\n",
        "ax2.set_title('bath')\n",
        "\n",
        "# Create the third boxplot for bhk\n",
        "ax3.boxplot(whole_new_df['size_bhk'])\n",
        "ax3.set_title('size_bhk')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b723d21",
      "metadata": {
        "id": "3b723d21"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_sqft(cf):\n",
        "    # create an empty dataframe to store the output\n",
        "    cf_result = pd.DataFrame()\n",
        "    # group the dataframe by location\n",
        "    for key, subcf in cf.groupby('location'):\n",
        "        # calculate the mean and standard deviation of the price_per_sqft column for the current location\n",
        "        m = np.mean(subcf.price_per_sqft)\n",
        "        sd = np.std(subcf.price_per_sqft)\n",
        "        # filter out the rows where price_per_sqft is greater than (mean - 3*std) and less than or equal to (mean + 3*std)\n",
        "        gen_cf = subcf[(subcf.price_per_sqft > (m-3*sd)) & (subcf.price_per_sqft <= (m+3*sd))]\n",
        "        # concatenate the filtered dataframe with the output dataframe\n",
        "        cf_result = pd.concat([cf_result, gen_cf], ignore_index=True)\n",
        "    # return the output dataframe\n",
        "    return cf_result\n",
        "\n",
        "# apply the remove_outliers_sqft function to the df dataframe\n",
        "whole_new1_df1 = remove_outliers_sqft(whole_new_df)\n",
        "\n",
        "whole_new1_df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0408570d",
      "metadata": {
        "id": "0408570d"
      },
      "outputs": [],
      "source": [
        "def bhk_remover_outlier(pf):\n",
        "    # create an empty array to store the indices of rows to be excluded\n",
        "    exclude_indices = np.array([])\n",
        "    # group the dataframe by location\n",
        "    for location, location_pf in pf.groupby('location'):\n",
        "        # create an empty dictionary to store the statistics for each BHK in the current location\n",
        "        bhk_stats = {}\n",
        "        # group the location dataframe by BHK and calculate the mean, std, and count for each BHK\n",
        "        for bhk, bhk_pf in location_pf.groupby('size_bhk'):\n",
        "            bhk_stats[bhk] = {\n",
        "                'mean': np.mean(bhk_pf.price_per_sqft),\n",
        "                'std': np.std(bhk_pf.price_per_sqft),\n",
        "                'count': bhk_pf.shape[0]\n",
        "            }\n",
        "        # iterate over each BHK in the current location\n",
        "        for bhk, bhk_pf in location_pf.groupby('size_bhk'):\n",
        "            # get the statistics for the previous BHK if it exists and has a count greater than 5\n",
        "            stats = bhk_stats.get(bhk-1)\n",
        "            if stats and stats['count'] > 5:\n",
        "                # exclude the rows where the price_per_sqft is less than the mean of the previous BHK\n",
        "                exclude_indices = np.append(exclude_indices, bhk_pf[bhk_pf.price_per_sqft < stats['mean']].index.values)\n",
        "    # drop the excluded rows from the original dataframe and return it\n",
        "    return pf.drop(exclude_indices, axis='index')\n",
        "\n",
        "# apply the bhk_remover_outlier function to the df dataframe\n",
        "whole_new2_df2 = bhk_remover_outlier(whole_new1_df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7183a7",
      "metadata": {
        "id": "0f7183a7"
      },
      "outputs": [],
      "source": [
        "whole_new2_df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc34ce1",
      "metadata": {
        "id": "1cc34ce1"
      },
      "outputs": [],
      "source": [
        "# Create a figure and three subplots for each boxplot\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,10))\n",
        "\n",
        "# Create the first boxplot for total_sqft\n",
        "ax1.boxplot(whole_new2_df2['total_sqft'])\n",
        "ax1.set_title('total_sqft 1')\n",
        "\n",
        "# Create the second boxplot for bath\n",
        "ax2.boxplot(whole_new2_df2['bath'])\n",
        "ax2.set_title('bath')\n",
        "\n",
        "# Create the third boxplot for bhk\n",
        "ax3.boxplot(whole_new2_df2['size_bhk'])\n",
        "ax3.set_title('size_bhk')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a64c99",
      "metadata": {
        "id": "07a64c99"
      },
      "outputs": [],
      "source": [
        "whole_new2_df2.drop(columns=['size','price_per_sqft','bhk_per_sqft'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35d3c33",
      "metadata": {
        "id": "e35d3c33"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(whole_new2_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f006f444",
      "metadata": {
        "id": "f006f444"
      },
      "outputs": [],
      "source": [
        "whole_new2_df2.to_csv(\"practice_cleaned_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5594a874",
      "metadata": {
        "id": "5594a874"
      },
      "outputs": [],
      "source": [
        "pp_df = pd.read_csv('practice_cleaned_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b67b66",
      "metadata": {
        "id": "43b67b66"
      },
      "outputs": [],
      "source": [
        "pp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe520cb4",
      "metadata": {
        "scrolled": true,
        "id": "fe520cb4"
      },
      "outputs": [],
      "source": [
        "pp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "998ddbac",
      "metadata": {
        "id": "998ddbac"
      },
      "outputs": [],
      "source": [
        "pp_df = pd.read_csv(\"practice_cleaned_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88535f3",
      "metadata": {
        "id": "a88535f3"
      },
      "outputs": [],
      "source": [
        "pp_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f71cea",
      "metadata": {
        "id": "68f71cea"
      },
      "source": [
        "# Model training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62eaa74",
      "metadata": {
        "id": "b62eaa74"
      },
      "outputs": [],
      "source": [
        "#importing all the necessary libraries to perform the ML task\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1236229c",
      "metadata": {
        "id": "1236229c"
      },
      "outputs": [],
      "source": [
        "x1 = pp_df.drop(columns=['price','Unnamed: 0'])\n",
        "y1 = pp_df['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d3834e",
      "metadata": {
        "id": "32d3834e"
      },
      "outputs": [],
      "source": [
        "x1_train,x1_test,y1_train,y1_test = train_test_split(x1, y1, test_size=0.25, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdfb474",
      "metadata": {
        "id": "4fdfb474"
      },
      "outputs": [],
      "source": [
        "column_transformer = make_column_transformer((OneHotEncoder(sparse=False),['location']), remainder ='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebbf867e",
      "metadata": {
        "id": "ebbf867e"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3afa088",
      "metadata": {
        "id": "e3afa088"
      },
      "outputs": [],
      "source": [
        "lr1 = LinearRegression(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbed6c0",
      "metadata": {
        "id": "cfbed6c0"
      },
      "outputs": [],
      "source": [
        "pipe6 = make_pipeline(column_transformer,scaler, lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a644d441",
      "metadata": {
        "id": "a644d441"
      },
      "outputs": [],
      "source": [
        "pipe6.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1196646",
      "metadata": {
        "id": "b1196646"
      },
      "outputs": [],
      "source": [
        "y1_prediction_lr1 = list(pipe6.predict(x1_test))\n",
        "r2_score(y1_test, y1_prediction_lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2d6669",
      "metadata": {
        "id": "cf2d6669"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_lr1 = mean_squared_error(y1_test, y1_prediction_lr1)\n",
        "mae_lr1 = mean_absolute_error(y1_test, y1_prediction_lr1)\n",
        "print(\"Mean Squared Error:\", mse_lr1)\n",
        "print(\"Mean Absolute Error:\", mae_lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab2edfa",
      "metadata": {
        "id": "eab2edfa"
      },
      "outputs": [],
      "source": [
        "ls1= Lasso()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c16670",
      "metadata": {
        "id": "87c16670"
      },
      "outputs": [],
      "source": [
        "pipe11 = make_pipeline(column_transformer, scaler, ls1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb3e187",
      "metadata": {
        "id": "0fb3e187"
      },
      "outputs": [],
      "source": [
        "pipe11.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d521713f",
      "metadata": {
        "id": "d521713f"
      },
      "outputs": [],
      "source": [
        "y1_prediction_ls1 = list(pipe11.predict(x1_test))\n",
        "r2_score(y1_test, y1_prediction_ls1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70718a1",
      "metadata": {
        "id": "f70718a1"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_ls1 = mean_squared_error(y1_test, y1_prediction_ls1)\n",
        "mae_ls1 = mean_absolute_error(y1_test, y1_prediction_ls1)\n",
        "print(\"Mean Squared Error:\", mse_ls1)\n",
        "print(\"Mean Absolute Error:\", mae_ls1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b993b5b5",
      "metadata": {
        "id": "b993b5b5"
      },
      "outputs": [],
      "source": [
        "rg1 = Ridge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741868b5",
      "metadata": {
        "id": "741868b5"
      },
      "outputs": [],
      "source": [
        "pipe7 = make_pipeline(column_transformer,scaler, rg1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831d714f",
      "metadata": {
        "id": "831d714f"
      },
      "outputs": [],
      "source": [
        "pipe7.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbeb45da",
      "metadata": {
        "id": "dbeb45da"
      },
      "outputs": [],
      "source": [
        "y1_prediction_rg1 = list(pipe7.predict(x1_test))\n",
        "r2_score(y1_test, y1_prediction_rg1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e29ba7a",
      "metadata": {
        "id": "9e29ba7a"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_rg1 = mean_squared_error(y1_test, y1_prediction_rg1)\n",
        "mae_rg1 = mean_absolute_error(y1_test, y1_prediction_rg1)\n",
        "print(\"Mean Squared Error:\", mse_rg1)\n",
        "print(\"Mean Absolute Error:\", mae_rg1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160a3c71",
      "metadata": {
        "id": "160a3c71"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311db19b",
      "metadata": {
        "id": "311db19b"
      },
      "outputs": [],
      "source": [
        "model1=SVR()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020381a0",
      "metadata": {
        "id": "020381a0"
      },
      "outputs": [],
      "source": [
        "pipe8 = make_pipeline(column_transformer,scaler, model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf482e1",
      "metadata": {
        "id": "ccf482e1"
      },
      "outputs": [],
      "source": [
        "pipe8.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a356f655",
      "metadata": {
        "id": "a356f655"
      },
      "outputs": [],
      "source": [
        "y1_prediction_svr = list(pipe8.predict(x1_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6873a5ee",
      "metadata": {
        "id": "6873a5ee"
      },
      "outputs": [],
      "source": [
        "pipe8.score(x1_test,y1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b928a6",
      "metadata": {
        "id": "b7b928a6"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_svr1 = mean_squared_error(y1_test, y1_prediction_svr)\n",
        "mae_svr1 = mean_absolute_error(y1_test, y1_prediction_svr)\n",
        "print(\"Mean Squared Error:\", mse_svr1)\n",
        "print(\"Mean Absolute Error:\", mae_svr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7616b2d0",
      "metadata": {
        "id": "7616b2d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c86edc1",
      "metadata": {
        "id": "1c86edc1"
      },
      "outputs": [],
      "source": [
        "rfr1 = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f3b462",
      "metadata": {
        "id": "34f3b462"
      },
      "outputs": [],
      "source": [
        "pipe9 = make_pipeline(column_transformer,scaler, rfr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a787f1bb",
      "metadata": {
        "id": "a787f1bb"
      },
      "outputs": [],
      "source": [
        "pipe9.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b206df2d",
      "metadata": {
        "id": "b206df2d"
      },
      "outputs": [],
      "source": [
        "y1_prediction_rf = list(pipe9.predict(x1_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e5331d",
      "metadata": {
        "id": "a9e5331d"
      },
      "outputs": [],
      "source": [
        "pipe9.score(x1_test,y1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24581762",
      "metadata": {
        "id": "24581762"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using mean squared error and mean absolute errro\n",
        "mse_rf1 = mean_squared_error(y1_test, y1_prediction_rf)\n",
        "mae_rf1 = mean_absolute_error(y1_test, y1_prediction_rf)\n",
        "print(\"Mean Squared Error:\", mse_rf1)\n",
        "print(\"Mean Absolute Error:\", mae_rf1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8353ea6",
      "metadata": {
        "id": "d8353ea6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import RANSACRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff34e17",
      "metadata": {
        "id": "1ff34e17"
      },
      "outputs": [],
      "source": [
        "ransac1 = RANSACRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "844494c5",
      "metadata": {
        "id": "844494c5"
      },
      "outputs": [],
      "source": [
        "pipe10 = make_pipeline(column_transformer,scaler, ransac1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736e99e7",
      "metadata": {
        "id": "736e99e7"
      },
      "outputs": [],
      "source": [
        "pipe10.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b67d55",
      "metadata": {
        "id": "85b67d55"
      },
      "outputs": [],
      "source": [
        "pipe10.score(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf7f14b0",
      "metadata": {
        "id": "cf7f14b0"
      },
      "source": [
        "# Comparison of the model's accuracy following the dataset's preprocessing in two distinct methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398dc9e2",
      "metadata": {
        "id": "398dc9e2"
      },
      "outputs": [],
      "source": [
        "print('Model Accuracy for the First Case Dataset')\n",
        "print()\n",
        "print('LinearRegression Accuracy:', r2_score(y_test, y_prediction_lr)*100)\n",
        "print('Lasso Accuracy:', r2_score(y_test, y_prediction_ls)*100)\n",
        "print('Ridge Accuracy:', r2_score(y_test, y_prediction_rg)*100)\n",
        "\n",
        "print('Support Vector Regressor Accuracy:', pipe4.score(x_test,y_test)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681d1059",
      "metadata": {
        "id": "681d1059"
      },
      "outputs": [],
      "source": [
        "print('Model Accuracy for the Second Case Dataset')\n",
        "print()\n",
        "print('LinearRegression Accuracy:', r2_score(y1_test, y1_prediction_lr1)*100)\n",
        "print('Lasso Accuracy:', r2_score(y1_test, y1_prediction_ls1)*100)\n",
        "print('Ridge Accuracy:', r2_score(y1_test, y1_prediction_rg1)*100)\n",
        "\n",
        "print('Support Vector Regressor Accuracy:', pipe8.score(x1_test,y1_test)*100)\n",
        "print('RandomForestRegressor Accuracy:', pipe9.score(x1_test,y1_test)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5db6de",
      "metadata": {
        "id": "af5db6de"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}